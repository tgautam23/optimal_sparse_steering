{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Method Comparison\n",
    "Head-to-head comparison of all steering methods on the same model + dataset setup.\n",
    "\n",
    "**Methods compared:**\n",
    "| Category | Method | Description |\n",
    "|----------|--------|-------------|\n",
    "| Control | NoSteering | Zero vector baseline |\n",
    "| Control | RandomDirection | Random unit vector |\n",
    "| CAA | CAAMeanDiff | Mean difference of class activations |\n",
    "| CAA | CAAContrastive | Contrastive prompt pairs |\n",
    "| CAA | CAARepE | Persona prefix contrast |\n",
    "| SAE | SingleFeature | Best correlated SAE feature |\n",
    "| SAE | TopKFeatures | Top-k correlated features |\n",
    "| Optimal | ConvexOptimal (SOCP) | SOCP with hard L2 constraint |\n",
    "| Optimal | QPOptimal (QP) | QP with L2 penalty |\n",
    "\n",
    "**Metrics:** Probe score delta, KL divergence, L0 sparsity, steering vector norm, downstream classifier accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title Setup\nimport sys, os\n\nIN_COLAB = 'google.colab' in sys.modules\nif IN_COLAB:\n    # Clone repo and install dependencies\n    if not os.path.exists('/content/optimal_sparse_steering'):\n        !git clone https://github.com/tgautam23/optimal_sparse_steering.git /content/optimal_sparse_steering\n    !pip install -q torch transformer-lens sae-lens cvxpy datasets scikit-learn matplotlib seaborn tqdm transformers pandas\n    PROJECT_ROOT = '/content/optimal_sparse_steering'\nelse:\n    PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n\nsys.path.insert(0, PROJECT_ROOT)\n\nimport logging\nimport numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\nfrom configs.base import ExperimentConfig, ModelConfig\nfrom src.models.wrapper import ModelWrapper\nfrom src.models.sae_utils import get_decoder_matrix\nfrom src.data.loader import load_dataset_splits\nfrom src.data.preprocessing import extract_activations, extract_sae_features\nfrom src.data.prompts import get_contrastive_pairs, get_persona_prefix, get_neutral_queries\nfrom src.probes.linear_probe import LinearProbe\nfrom src.steering.no_steering import NoSteering\nfrom src.steering.random_direction import RandomDirection\nfrom src.steering.caa import CAAMeanDiff, CAAContrastive, CAARepE\nfrom src.steering.single_feature import SingleFeature\nfrom src.steering.topk_features import TopKFeatures\nfrom src.steering.convex_optimal import ConvexOptimalSteering\nfrom src.steering.qp_optimal import QPOptimalSteering\nfrom src.evaluation.metrics import compute_probe_score, compute_kl_divergence, compute_l0\nfrom src.evaluation.generation import steered_generation, steered_forward\n\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(name)s: %(message)s')\nsns.set_theme(style=\"whitegrid\")\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device: {device}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## GPT-2 Small + SST-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load Model + Data + Probe + SAE Features\n",
    "config = ExperimentConfig()\n",
    "config.model.device = device\n",
    "target_class = 1\n",
    "alpha = 5.0  # default steering strength for comparison\n",
    "\n",
    "model_wrapper = ModelWrapper(config.model)\n",
    "layer = config.model.steering_layer\n",
    "sae = model_wrapper.get_sae(layer)\n",
    "D = get_decoder_matrix(sae)\n",
    "d_sae, d_model = D.shape\n",
    "\n",
    "data = load_dataset_splits(config.data)\n",
    "print(f\"Train: {len(data['train_texts'])}, Test: {len(data['test_texts'])}\")\n",
    "\n",
    "# Activations\n",
    "train_acts = extract_activations(data['train_texts'], model_wrapper, layer,\n",
    "                                  batch_size=config.model.batch_size)\n",
    "test_acts = extract_activations(data['test_texts'], model_wrapper, layer,\n",
    "                                 batch_size=config.model.batch_size)\n",
    "\n",
    "# SAE features (needed for SAE-based methods)\n",
    "train_sae = extract_sae_features(data['train_texts'], model_wrapper, layer,\n",
    "                                  batch_size=config.model.batch_size)\n",
    "test_sae = extract_sae_features(data['test_texts'], model_wrapper, layer,\n",
    "                                 batch_size=config.model.batch_size)\n",
    "\n",
    "train_np = train_acts.numpy()\n",
    "test_np = test_acts.numpy()\n",
    "train_labels = np.array(data['train_labels'])\n",
    "test_labels = np.array(data['test_labels'])\n",
    "\n",
    "# Probe\n",
    "probe = LinearProbe(d_model=d_model)\n",
    "probe.fit(train_np, train_labels)\n",
    "print(f\"Probe accuracy \\u2014 train: {probe.score(train_np, train_labels):.4f}, \"\n",
    "      f\"test: {probe.score(test_np, test_labels):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run All Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Compute All Steering Vectors\n",
    "methods = {}\n",
    "pos_mask = train_labels == target_class\n",
    "neg_mask = ~pos_mask\n",
    "\n",
    "# 1. No Steering\n",
    "ns = NoSteering()\n",
    "ns.compute_steering_vector(d_model=d_model)\n",
    "methods['NoSteering'] = ns\n",
    "\n",
    "# 2. Random Direction\n",
    "rd = RandomDirection(seed=42)\n",
    "rd.compute_steering_vector(d_model=d_model)\n",
    "methods['Random'] = rd\n",
    "\n",
    "# 3. CAAMeanDiff\n",
    "md = CAAMeanDiff()\n",
    "md.compute_steering_vector(\n",
    "    activations_pos=torch.tensor(train_np[pos_mask]),\n",
    "    activations_neg=torch.tensor(train_np[neg_mask]),\n",
    ")\n",
    "methods['CAAMeanDiff'] = md\n",
    "\n",
    "# 4. CAAContrastive\n",
    "cc = CAAContrastive()\n",
    "cc.compute_steering_vector(\n",
    "    model_wrapper=model_wrapper, layer=layer,\n",
    "    contrastive_pairs=get_contrastive_pairs(\"sst2\"),\n",
    "    batch_size=config.model.batch_size,\n",
    ")\n",
    "methods['CAAContrastive'] = cc\n",
    "\n",
    "# 5. CAARepE\n",
    "repe = CAARepE()\n",
    "repe.compute_steering_vector(\n",
    "    model_wrapper=model_wrapper, layer=layer,\n",
    "    neutral_queries=get_neutral_queries(\"sst2\")[:20],\n",
    "    positive_prefix=get_persona_prefix(\"sst2\", 1),\n",
    "    negative_prefix=get_persona_prefix(\"sst2\", 0),\n",
    "    batch_size=config.model.batch_size,\n",
    ")\n",
    "methods['CAARepE'] = repe\n",
    "\n",
    "# 6. SingleFeature (best correlated)\n",
    "train_sae_np = train_sae.numpy()\n",
    "feat_centered = train_sae_np - train_sae_np.mean(axis=0, keepdims=True)\n",
    "labels_centered = train_labels - train_labels.mean()\n",
    "numerator = feat_centered.T @ labels_centered\n",
    "feat_std = np.sqrt((feat_centered ** 2).sum(axis=0) + 1e-10)\n",
    "label_std = np.sqrt((labels_centered ** 2).sum() + 1e-10)\n",
    "correlations = numerator / (feat_std * label_std)\n",
    "best_feat = int(np.argmax(correlations))  # most positively correlated\n",
    "\n",
    "sf = SingleFeature(feature_idx=best_feat)\n",
    "sf.compute_steering_vector(model_wrapper=model_wrapper, layer=layer)\n",
    "methods['SingleFeature'] = sf\n",
    "\n",
    "# 7. TopKFeatures (k=10)\n",
    "tk = TopKFeatures(topk=10)\n",
    "tk.compute_steering_vector(\n",
    "    sae_features=train_sae, labels=train_labels,\n",
    "    model_wrapper=model_wrapper, layer=layer,\n",
    ")\n",
    "methods['TopK(k=10)'] = tk\n",
    "\n",
    "# 8. SOCP\n",
    "socp = ConvexOptimalSteering(epsilon=5.0, tau=0.5, solver=\"SCS\")\n",
    "socp.compute_steering_vector(\n",
    "    h=torch.tensor(test_np[0]), probe_w=probe.weight_vector, probe_b=probe.bias,\n",
    "    D=D, sae_features=test_sae[0], target_class=target_class,\n",
    ")\n",
    "methods['SOCP'] = socp\n",
    "\n",
    "# 9. QP\n",
    "qp = QPOptimalSteering(lam=1.0, tau=0.5, solver=\"SCS\", prefilter_topk=2000)\n",
    "qp.compute_steering_vector(\n",
    "    h=torch.tensor(test_np[0]), probe_w=probe.weight_vector, probe_b=probe.bias,\n",
    "    D=D, sae_features=test_sae[0], target_class=target_class,\n",
    ")\n",
    "methods['QP'] = qp\n",
    "\n",
    "print(f\"Computed {len(methods)} steering vectors.\")\n",
    "for name, m in methods.items():\n",
    "    norm = m.steering_vector.norm().item()\n",
    "    print(f\"  {name:20s}  norm={norm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Evaluate All Methods\n",
    "rows = []\n",
    "\n",
    "for name, method in methods.items():\n",
    "    sv = method.steering_vector.numpy()\n",
    "    steered = test_np + alpha * sv[np.newaxis, :]\n",
    "\n",
    "    base_score = compute_probe_score(probe, test_np, target_class)\n",
    "    steered_score = compute_probe_score(probe, steered, target_class)\n",
    "\n",
    "    # L0 sparsity (for SAE-based methods)\n",
    "    l0 = None\n",
    "    if hasattr(method, '_delta') and method._delta is not None:\n",
    "        l0 = compute_l0(method._delta)\n",
    "\n",
    "    # KL divergence (sample a few texts)\n",
    "    kl_vals = []\n",
    "    tokenizer = model_wrapper.tokenizer\n",
    "    for text in data['test_texts'][:5]:\n",
    "        try:\n",
    "            tokens = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
    "                               max_length=128)\n",
    "            input_ids = tokens[\"input_ids\"].to(device)\n",
    "\n",
    "            logits_steered, _ = steered_forward(\n",
    "                model_wrapper, input_ids, method, layer, alpha=alpha,\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                logits_base = model_wrapper.model(input_ids)\n",
    "\n",
    "            kl = compute_kl_divergence(logits_steered, logits_base)\n",
    "            kl_vals.append(kl)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    kl_mean = float(np.mean(kl_vals)) if kl_vals else None\n",
    "\n",
    "    rows.append({\n",
    "        'Method': name,\n",
    "        'Probe Delta': steered_score - base_score,\n",
    "        'Steering Norm': float(method.steering_vector.norm().item()),\n",
    "        'L0': l0,\n",
    "        'KL Divergence': kl_mean,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Probe Score Delta \\u2014 All Methods\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "colors = {\n",
    "    'NoSteering': '#95a5a6', 'Random': '#95a5a6',\n",
    "    'CAAMeanDiff': '#3498db', 'CAAContrastive': '#2980b9', 'CAARepE': '#1abc9c',\n",
    "    'SingleFeature': '#f39c12', 'TopK(k=10)': '#e67e22',\n",
    "    'SOCP': '#e74c3c', 'QP': '#c0392b',\n",
    "}\n",
    "\n",
    "method_names = df['Method'].tolist()\n",
    "deltas = df['Probe Delta'].tolist()\n",
    "bar_colors = [colors.get(name, '#7f8c8d') for name in method_names]\n",
    "\n",
    "bars = ax.bar(range(len(method_names)), deltas, color=bar_colors, edgecolor='white', linewidth=0.5)\n",
    "ax.set_xticks(range(len(method_names)))\n",
    "ax.set_xticklabels(method_names, rotation=30, ha='right')\n",
    "ax.set_ylabel('Probe Score Delta')\n",
    "ax.set_title(f'GPT-2 Small + SST-2: Steering Effectiveness (alpha={alpha})')\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, deltas):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.005,\n",
    "            f'{val:+.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Effectiveness vs Sparsity (SAE methods only)\n",
    "sae_methods = df[df['L0'].notna()].copy()\n",
    "\n",
    "if len(sae_methods) > 0:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "    for _, row in sae_methods.iterrows():\n",
    "        color = colors.get(row['Method'], '#7f8c8d')\n",
    "        ax.scatter(row['L0'], row['Probe Delta'], c=color, s=120, zorder=3, edgecolors='black')\n",
    "        ax.annotate(row['Method'], (row['L0'], row['Probe Delta']),\n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "    ax.set_xlabel('L0 (Number of Active SAE Features)')\n",
    "    ax.set_ylabel('Probe Score Delta')\n",
    "    ax.set_title('Sparsity vs Effectiveness (SAE-based Methods)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No SAE methods with L0 data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title KL Divergence Comparison\n",
    "df_kl = df[df['KL Divergence'].notna()].copy()\n",
    "\n",
    "if len(df_kl) > 0:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "    bar_colors_kl = [colors.get(name, '#7f8c8d') for name in df_kl['Method']]\n",
    "    ax.bar(range(len(df_kl)), df_kl['KL Divergence'], color=bar_colors_kl, edgecolor='white')\n",
    "    ax.set_xticks(range(len(df_kl)))\n",
    "    ax.set_xticklabels(df_kl['Method'], rotation=30, ha='right')\n",
    "    ax.set_ylabel('KL Divergence')\n",
    "    ax.set_title(f'Distribution Shift: KL(steered || base) at alpha={alpha}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Text Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Generated Text Samples\n",
    "queries = get_neutral_queries(\"sst2\")[:3]\n",
    "gen_alpha = 5.0\n",
    "\n",
    "print(f\"Steering alpha = {gen_alpha}\")\n",
    "print(f\"Prompts: {queries}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, method in methods.items():\n",
    "    if name == 'NoSteering':\n",
    "        continue\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    try:\n",
    "        gens = steered_generation(model_wrapper, queries, method, layer,\n",
    "                                   alpha=gen_alpha, max_new_tokens=50, temperature=0.7)\n",
    "        for i, g in enumerate(gens):\n",
    "            print(f\"  [{i+1}] {g[:200]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Sweep \\u2014 All Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Alpha Sweep \\u2014 All Methods\n",
    "alpha_values = [0.0, 1.0, 2.0, 3.0, 5.0, 7.0, 10.0, 15.0]\n",
    "sweep_results = {}\n",
    "\n",
    "for name, method in methods.items():\n",
    "    sv = method.steering_vector.numpy()\n",
    "    method_results = []\n",
    "    for a in alpha_values:\n",
    "        steered = test_np + a * sv[np.newaxis, :]\n",
    "        base_s = compute_probe_score(probe, test_np, target_class)\n",
    "        steer_s = compute_probe_score(probe, steered, target_class)\n",
    "        method_results.append({'alpha': a, 'probe_delta': steer_s - base_s})\n",
    "    sweep_results[name] = method_results\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "linestyles = {\n",
    "    'NoSteering': '--', 'Random': ':',\n",
    "    'CAAMeanDiff': '-', 'CAAContrastive': '-', 'CAARepE': '-',\n",
    "    'SingleFeature': '-.', 'TopK(k=10)': '-.',\n",
    "    'SOCP': '-', 'QP': '-',\n",
    "}\n",
    "\n",
    "for name, results in sweep_results.items():\n",
    "    alphas = [r['alpha'] for r in results]\n",
    "    deltas = [r['probe_delta'] for r in results]\n",
    "    color = colors.get(name, '#7f8c8d')\n",
    "    ls = linestyles.get(name, '-')\n",
    "    lw = 2.5 if name in ('SOCP', 'QP') else 1.5\n",
    "    ax.plot(alphas, deltas, marker='o', color=color, linestyle=ls,\n",
    "            linewidth=lw, markersize=4, label=name)\n",
    "\n",
    "ax.set_xlabel('Alpha (steering strength)')\n",
    "ax.set_ylabel('Probe Score Delta')\n",
    "ax.set_title('GPT-2 Small + SST-2: All Methods \\u2014 Steering Effectiveness vs Alpha')\n",
    "ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left', fontsize=9)\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Final Summary\n",
    "print(\"=\" * 90)\n",
    "print(f\"{'Method':20s} | {'Probe Delta':>12s} | {'L0':>6s} | {'KL Div':>10s} | {'Norm':>8s}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    l0_str = f\"{row['L0']:6d}\" if row['L0'] is not None else \"   N/A\"\n",
    "    kl_str = f\"{row['KL Divergence']:10.4f}\" if row['KL Divergence'] is not None else \"       N/A\"\n",
    "    print(f\"{row['Method']:20s} | {row['Probe Delta']:+12.4f} | {l0_str} | {kl_str} | {row['Steering Norm']:8.4f}\")\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(f\"\\nKey: Probe Delta = shift in P(target_class) at alpha={alpha}\")\n",
    "print(\"     L0 = number of active SAE features (sparsity)\")\n",
    "print(\"     KL Div = KL divergence between steered and base distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "- **Control baselines** (NoSteering, Random) confirm that steering requires meaningful directions\n",
    "- **CAA methods** are effective and don't require SAE access, but produce dense (non-sparse) steering vectors\n",
    "- **SAE heuristic methods** (SingleFeature, TopK) offer interpretability but effectiveness depends on feature selection quality\n",
    "- **Convex optimal methods** (SOCP, QP) achieve competitive effectiveness with *minimal* feature interventions \\u2014 the key advantage is extreme sparsity\n",
    "- The **QP formulation** trades a hard L2 constraint for a penalty, enabling warm-starting and a cleaner hyperparameter (lambda)"
   ]
  }
 ]
}