{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0",
   "mimetype": "text/x-python",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Sparse Steering via Convex Optimization\n",
    "\n",
    "This notebook demonstrates two convex-optimization formulations for finding the **sparsest SAE feature intervention** that steers model behavior:\n",
    "\n",
    "- **SOCP** (Second-Order Cone Program): minimizes $\\ell_1$ subject to a hard $\\ell_2$ coherence constraint $\\|D^\\top \\delta\\|_2 \\leq \\epsilon$.\n",
    "- **QP** (Quadratic Program): minimizes $\\ell_1 + \\frac{\\lambda}{2}\\|D^\\top \\delta\\|_2^2$, supporting warm-starting across sequential solves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Setup\n",
    "import sys, os\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    REPO_DIR = '/content/optimal_sparse_steering'\n",
    "    if os.path.exists(REPO_DIR):\n",
    "        !git -C {REPO_DIR} pull -q\n",
    "    else:\n",
    "        !git clone -q https://github.com/tgautam23/optimal_sparse_steering.git {REPO_DIR}\n",
    "    !pip install -q torch transformer-lens sae-lens cvxpy datasets scikit-learn matplotlib seaborn tqdm transformers 2>&1 | grep -v \"dependency conflicts\\|incompatible\\|pip's dependency resolver\"\n",
    "    PROJECT_ROOT = REPO_DIR\n",
    "    try:\n",
    "        import numpy as _np; import seaborn as _sns; del _np, _sns\n",
    "    except (ValueError, ImportError):\n",
    "        print(\"Restarting runtime for numpy compatibility...\")\n",
    "        os.kill(os.getpid(), 9)\n",
    "else:\n",
    "    PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from configs.base import ExperimentConfig, ModelConfig, DataConfig\n",
    "from src.models.wrapper import ModelWrapper\n",
    "from src.models.sae_utils import get_decoder_matrix\n",
    "from src.data.loader import load_dataset_splits\n",
    "from src.data.preprocessing import extract_activations, extract_sae_features\n",
    "from src.probes.linear_probe import LinearProbe\n",
    "from src.steering.convex_optimal import ConvexOptimalSteering\n",
    "from src.steering.qp_optimal import QPOptimalSteering\n",
    "from src.evaluation.metrics import compute_probe_score, compute_l0\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(name)s: %(message)s')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Sentiment Steering (GPT-2 Small + SST-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load Model, Data, Probe, and Decoder Matrix\n",
    "config = ExperimentConfig()\n",
    "config.model.device = device\n",
    "config.data.split = \"train\"\n",
    "config.data.max_samples_per_class = 500\n",
    "\n",
    "# Load model\n",
    "model_wrapper = ModelWrapper(config.model)\n",
    "layer = config.model.steering_layer\n",
    "print(f\"Model: {config.model.tl_name}, d_model={config.model.d_model}, steering_layer={layer}\")\n",
    "\n",
    "# Load SAE and get decoder matrix\n",
    "sae = model_wrapper.get_sae(layer)\n",
    "D = get_decoder_matrix(sae)\n",
    "print(f\"SAE decoder matrix D shape: {D.shape}\")\n",
    "\n",
    "# Load dataset splits\n",
    "data = load_dataset_splits(config.data)\n",
    "print(f\"Train: {len(data['train_texts'])}, Test: {len(data['test_texts'])}\")\n",
    "\n",
    "# Extract activations at the steering layer\n",
    "train_acts = extract_activations(data['train_texts'], model_wrapper, layer, batch_size=config.model.batch_size)\n",
    "test_acts = extract_activations(data['test_texts'], model_wrapper, layer, batch_size=config.model.batch_size)\n",
    "\n",
    "train_np = train_acts.numpy()\n",
    "test_np = test_acts.numpy()\n",
    "train_labels = np.array(data['train_labels'])\n",
    "test_labels = np.array(data['test_labels'])\n",
    "\n",
    "# Train linear probe with C=0.01 for better regularization\n",
    "probe = LinearProbe(d_model=config.model.d_model, C=0.01)\n",
    "probe.fit(train_np, train_labels)\n",
    "print(f\"Probe accuracy -- train: {probe.score(train_np, train_labels):.4f}, \"\n",
    "      f\"test: {probe.score(test_np, test_labels):.4f}\")\n",
    "\n",
    "# Extract probe parameters\n",
    "probe_w = probe.weight_vector\n",
    "probe_b = probe.bias\n",
    "target_class = 1\n",
    "print(f\"Probe weight norm: {np.linalg.norm(probe_w):.4f}, bias: {probe_b:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neutral Prompts & Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define Prompts and Helper Functions\n",
    "sentiment_prompts = [\n",
    "    \"The movie was\",\n",
    "    \"I think the food at this restaurant is\",\n",
    "    \"After reading the book, I felt that it\",\n",
    "    \"The weather today seems\",\n",
    "    \"My experience with the new product has been\",\n",
    "]\n",
    "\n",
    "alpha_values = [0, 1, 5, 10]\n",
    "\n",
    "\n",
    "def compute_generation_probe_score(text, model_wrapper, probe, layer, target_class=1):\n",
    "    \"\"\"Compute probe score on generated text (unsteered forward pass).\"\"\"\n",
    "    tokenizer = model_wrapper.tokenizer\n",
    "    model = model_wrapper.model\n",
    "    device_m = next(model.parameters()).device\n",
    "    hook_name = f\"blocks.{layer}.hook_resid_pre\"\n",
    "\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", truncation=True, max_length=128).to(device_m)\n",
    "    with torch.no_grad():\n",
    "        _, cache = model_wrapper.run_with_cache(input_ids, names_filter=hook_name)\n",
    "    h = cache[hook_name][0, -1, :].cpu().numpy().reshape(1, -1)\n",
    "    score = probe.predict_proba(h)[0, target_class]\n",
    "    return float(score)\n",
    "\n",
    "\n",
    "def run_steering_experiment(prompts, method, model_wrapper, layer, probe, probe_w, probe_b,\n",
    "                            D, target_class, alpha_values, max_new_tokens=50):\n",
    "    \"\"\"Solve once per prompt, generate at multiple alpha values, return results.\"\"\"\n",
    "    model = model_wrapper.model\n",
    "    tokenizer = model_wrapper.tokenizer\n",
    "    hook_name = model_wrapper.get_hook_name(layer)\n",
    "    device_m = next(model.parameters()).device\n",
    "\n",
    "    all_results = []\n",
    "    all_active_features = []\n",
    "\n",
    "    for prompt in prompts:\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device_m)\n",
    "\n",
    "        # Extract last-token activation + SAE features\n",
    "        with torch.no_grad():\n",
    "            _, cache = model_wrapper.run_with_cache(input_ids, names_filter=hook_name)\n",
    "        h = cache[hook_name][0, -1, :].cpu()\n",
    "        sae_feats = model_wrapper.encode_with_sae(h.unsqueeze(0), layer).squeeze(0)\n",
    "\n",
    "        # Solve optimization once\n",
    "        t0 = time.time()\n",
    "        sv = method.compute_steering_vector(\n",
    "            h=h, probe_w=probe_w, probe_b=probe_b,\n",
    "            D=D, sae_features=sae_feats, target_class=target_class,\n",
    "        )\n",
    "        solve_time = getattr(method, '_solve_time', None)\n",
    "        if solve_time is None:\n",
    "            solve_time = time.time() - t0\n",
    "\n",
    "        active_feats = method.active_features.tolist() if hasattr(method, 'active_features') and method._active_features is not None else []\n",
    "        l0 = int((method.delta > 1e-6).sum()) if hasattr(method, 'delta') and method._delta is not None else 0\n",
    "        all_active_features.append(set(active_feats))\n",
    "\n",
    "        prompt_results = {\"prompt\": prompt, \"solve_time\": solve_time, \"l0\": l0, \"active_features\": active_feats, \"generations\": {}}\n",
    "\n",
    "        sv_device = sv.to(device_m)\n",
    "\n",
    "        for alpha in alpha_values:\n",
    "            if alpha == 0:\n",
    "                # Unsteered generation\n",
    "                def hook_fn(acts, hook):\n",
    "                    return acts\n",
    "            else:\n",
    "                def hook_fn(acts, hook, _sv=sv_device, _alpha=alpha):\n",
    "                    return acts + _alpha * _sv\n",
    "\n",
    "            model.add_hook(hook_name, hook_fn)\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    output_ids = model.generate(\n",
    "                        input_ids, max_new_tokens=max_new_tokens,\n",
    "                        temperature=0.7, top_p=0.9, do_sample=True,\n",
    "                    )\n",
    "            finally:\n",
    "                model.reset_hooks()\n",
    "\n",
    "            gen_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "            probe_score = compute_generation_probe_score(gen_text, model_wrapper, probe, layer, target_class)\n",
    "\n",
    "            prompt_results[\"generations\"][alpha] = {\n",
    "                \"text\": gen_text,\n",
    "                \"probe_score\": probe_score,\n",
    "            }\n",
    "\n",
    "        all_results.append(prompt_results)\n",
    "\n",
    "    return all_results, all_active_features\n",
    "\n",
    "\n",
    "def display_results(results, method_name):\n",
    "    \"\"\"Print results in a readable format.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{method_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    for r in results:\n",
    "        print(f\"\\nPrompt: \\\"{r['prompt']}\\\"\")\n",
    "        print(f\"  Solve time: {r['solve_time']:.3f}s | L0: {r['l0']} active features\")\n",
    "        for alpha, gen in r['generations'].items():\n",
    "            score_str = f\"{gen['probe_score']:.4f}\"\n",
    "            text_preview = gen['text'][:120].replace('\\n', ' ')\n",
    "            print(f\"  alpha={alpha:2d} | P(target)={score_str} | {text_preview}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOCP Steering\n",
    "Solve the SOCP (hard $\\ell_2$ coherence constraint $\\|D^\\top \\delta\\|_2 \\leq \\epsilon$) once per prompt, then generate at each alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title SOCP Steering -- Sentiment\nsocp = ConvexOptimalSteering(epsilon=5.0, tau=0.5, solver=\"SCS\", prefilter_topk=2000)\n\nsocp_results, socp_features = run_steering_experiment(\n    sentiment_prompts, socp, model_wrapper, layer, probe, probe_w, probe_b,\n    D, target_class=1, alpha_values=alpha_values,\n)\n\ndisplay_results(socp_results, \"SOCP (epsilon=5.0)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QP Steering (with Warm-Start)\n",
    "Solve the QP ($\\ell_1$ + $\\frac{\\lambda}{2}\\|D^\\top \\delta\\|_2^2$ penalty) with warm-starting across prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title QP Steering -- Sentiment\n",
    "qp = QPOptimalSteering(lam=1.0, tau=0.5, solver=\"SCS\", prefilter_topk=2000, warm_start=True)\n",
    "\n",
    "qp_results, qp_features = run_steering_experiment(\n",
    "    sentiment_prompts, qp, model_wrapper, layer, probe, probe_w, probe_b,\n",
    "    D, target_class=1, alpha_values=alpha_values,\n",
    ")\n",
    "\n",
    "display_results(qp_results, \"QP (lambda=1.0, warm-start)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probe Score Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Probe Scores: SOCP vs QP across Alpha\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, (name, results) in zip(axes, [(\"SOCP\", socp_results), (\"QP\", qp_results)]):\n",
    "    for r in results:\n",
    "        scores = [r['generations'][a]['probe_score'] for a in alpha_values]\n",
    "        ax.plot(alpha_values, scores, marker='o', label=r['prompt'][:30] + \"...\")\n",
    "    ax.set_xlabel('Alpha')\n",
    "    ax.set_ylabel('P(positive sentiment)')\n",
    "    ax.set_title(f'{name}: Probe Score vs Alpha')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Intersection & Interpretability\n",
    "Find SAE features that are active across all solutions and look them up on Neuronpedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Feature Intersection Analysis\n",
    "print(\"SOCP: Active features per prompt\")\n",
    "for r, feats in zip(socp_results, socp_features):\n",
    "    print(f\"  \\\"{r['prompt'][:40]}...\\\" -> {len(feats)} features: {sorted(list(feats))[:10]}...\")\n",
    "\n",
    "print(f\"\\nQP: Active features per prompt\")\n",
    "for r, feats in zip(qp_results, qp_features):\n",
    "    print(f\"  \\\"{r['prompt'][:40]}...\\\" -> {len(feats)} features: {sorted(list(feats))[:10]}...\")\n",
    "\n",
    "# Intersection: features active in ALL SOCP solutions\n",
    "socp_intersection = set.intersection(*socp_features) if socp_features else set()\n",
    "qp_intersection = set.intersection(*qp_features) if qp_features else set()\n",
    "all_intersection = socp_intersection | qp_intersection  # union of both intersections\n",
    "\n",
    "print(f\"\\nSOCP features active in ALL prompts: {sorted(socp_intersection)}\")\n",
    "print(f\"QP features active in ALL prompts: {sorted(qp_intersection)}\")\n",
    "print(f\"Combined (union of intersections): {sorted(all_intersection)}\")\n",
    "\n",
    "# Neuronpedia links for GPT-2 Small JB SAEs\n",
    "print(f\"\\n--- Neuronpedia Links (layer {layer}) ---\")\n",
    "for feat_idx in sorted(all_intersection):\n",
    "    url = f\"https://www.neuronpedia.org/gpt2-small/{layer}-res-jb/{feat_idx}\"\n",
    "    print(f\"  Feature {feat_idx}: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Toxicity Steering (GPT-2 Small + Civil Comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Load Toxicity Data + Train Probe\n",
    "toxicity_config = DataConfig(\n",
    "    dataset_name=\"toxicity\",\n",
    "    hf_path=\"google/civil_comments\",\n",
    "    split=\"train\",\n",
    "    text_col=\"text\",\n",
    "    label_col=\"toxicity\",\n",
    "    toxicity_threshold=0.5,\n",
    "    max_samples_per_class=500,\n",
    "    probe_train_ratio=0.8,\n",
    "    max_seq_len=128,\n",
    ")\n",
    "\n",
    "tox_data = load_dataset_splits(toxicity_config)\n",
    "print(f\"Toxicity -- Train: {len(tox_data['train_texts'])}, Test: {len(tox_data['test_texts'])}\")\n",
    "\n",
    "# Extract activations\n",
    "tox_train_acts = extract_activations(tox_data['train_texts'], model_wrapper, layer, batch_size=8)\n",
    "tox_test_acts = extract_activations(tox_data['test_texts'], model_wrapper, layer, batch_size=8)\n",
    "\n",
    "tox_train_np = tox_train_acts.numpy()\n",
    "tox_test_np = tox_test_acts.numpy()\n",
    "tox_train_labels = np.array(tox_data['train_labels'])\n",
    "tox_test_labels = np.array(tox_data['test_labels'])\n",
    "\n",
    "# Train toxicity probe\n",
    "tox_probe = LinearProbe(d_model=config.model.d_model, C=0.01)\n",
    "tox_probe.fit(tox_train_np, tox_train_labels)\n",
    "print(f\"Toxicity probe -- train: {tox_probe.score(tox_train_np, tox_train_labels):.4f}, \"\n",
    "      f\"test: {tox_probe.score(tox_test_np, tox_test_labels):.4f}\")\n",
    "\n",
    "tox_probe_w = tox_probe.weight_vector\n",
    "tox_probe_b = tox_probe.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# @title Toxicity Steering\ntoxicity_prompts = [\n    \"I think people who disagree are\",\n    \"The problem with the government is that\",\n    \"When someone makes me angry, I want to\",\n    \"My honest opinion about this group is\",\n    \"The reason everything is failing is because\",\n]\n\n# SOCP\ntox_socp = ConvexOptimalSteering(epsilon=5.0, tau=0.5, solver=\"SCS\", prefilter_topk=2000)\ntox_socp_results, tox_socp_features = run_steering_experiment(\n    toxicity_prompts, tox_socp, model_wrapper, layer, tox_probe, tox_probe_w, tox_probe_b,\n    D, target_class=1, alpha_values=alpha_values,\n)\ndisplay_results(tox_socp_results, \"SOCP -- Toxicity (epsilon=5.0)\")\n\n# QP\ntox_qp = QPOptimalSteering(lam=1.0, tau=0.5, solver=\"SCS\", prefilter_topk=2000, warm_start=True)\ntox_qp_results, tox_qp_features = run_steering_experiment(\n    toxicity_prompts, tox_qp, model_wrapper, layer, tox_probe, tox_probe_w, tox_probe_b,\n    D, target_class=1, alpha_values=alpha_values,\n)\ndisplay_results(tox_qp_results, \"QP -- Toxicity (lambda=1.0)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Toxicity: Probe Scores & Feature Analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, (name, results) in zip(axes, [(\"SOCP\", tox_socp_results), (\"QP\", tox_qp_results)]):\n",
    "    for r in results:\n",
    "        scores = [r['generations'][a]['probe_score'] for a in alpha_values]\n",
    "        ax.plot(alpha_values, scores, marker='o', label=r['prompt'][:30] + \"...\")\n",
    "    ax.set_xlabel('Alpha')\n",
    "    ax.set_ylabel('P(toxic)')\n",
    "    ax.set_title(f'{name}: Toxicity Score vs Alpha')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature intersection\n",
    "tox_socp_inter = set.intersection(*tox_socp_features) if tox_socp_features else set()\n",
    "tox_qp_inter = set.intersection(*tox_qp_features) if tox_qp_features else set()\n",
    "tox_all_inter = tox_socp_inter | tox_qp_inter\n",
    "\n",
    "print(f\"\\nToxicity -- SOCP features in ALL prompts: {sorted(tox_socp_inter)}\")\n",
    "print(f\"Toxicity -- QP features in ALL prompts: {sorted(tox_qp_inter)}\")\n",
    "print(f\"\\n--- Neuronpedia Links (layer {layer}) ---\")\n",
    "for feat_idx in sorted(tox_all_inter):\n",
    "    url = f\"https://www.neuronpedia.org/gpt2-small/{layer}-res-jb/{feat_idx}\"\n",
    "    print(f\"  Feature {feat_idx}: {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "- Both SOCP and QP find extremely sparse solutions (typically 3-15 active features out of ~24k)\n",
    "- Higher alpha increases probe score shift but may degrade generation quality\n",
    "- The QP formulation benefits from warm-starting across prompts\n",
    "- Feature intersection analysis reveals which SAE features are consistently selected for a given attribute -- these can be inspected on Neuronpedia for interpretability"
   ]
  }
 ]
}